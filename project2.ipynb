{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 2"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Clustering Gaussian Blobs using $k$-means"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate 5 Gaussian blobs in 10 dimensions\n",
        "X, y_true = make_blobs(\n",
        "    n_samples=1000,\n",
        "    centers=5,\n",
        "    n_features=10,\n",
        "    cluster_std=1.5,\n",
        "    random_state=1)        # reproducibility\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "print(type(X),X.shape)\n",
        "print(type(y_true),y_true.shape)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import seaborn as sns\n",
        "\n",
        "#Computing inertia values\n",
        "inertia_values = []\n",
        "k_range = range(1,11)\n",
        "\n",
        "for k in k_range:\n",
        "  kmeans = KMeans(n_clusters = k).fit(X)\n",
        "  inertia_values.append(kmeans.inertia_)\n",
        "  print(\"inertia value for k-means=\", k, \"is\", inertia_values[k-1])\n",
        "\n",
        "#initialize PCA to 2 components\n",
        "pca = PCA(n_components = 2)\n",
        "principal_components = pca.fit_transform(X)\n",
        "\n",
        "#initialize KMeans\n",
        "kmeans = KMeans(n_clusters = 5)\n",
        "kmeans.fit(X)\n",
        "\n",
        "#cluster labels\n",
        "labels = kmeans.labels_\n",
        "\n",
        "centers = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "#plot results with PCA scaling\n",
        "plt.scatter(principal_components[:,0], principal_components[:,1], c = labels, cmap='viridis', marker='o')\n",
        "plt.scatter(centers[:,0], centers[:,1], c='red', marker = 'x', label = 'Centers')\n",
        "plt.title(\"2D PCA Visualization of K-Means Clustering\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.legend()\n",
        "plt.savefig(\"PCA_vis_kcluster_blobs.png\")\n",
        "plt.show()\n",
        "\n",
        "#confusion matrix\n",
        "cm = confusion_matrix(y_true, labels)\n",
        "\n",
        "#match clusters to actual using hungarian matching algorithm\n",
        "row_ind, col_ind = linear_sum_assignment(-cm)\n",
        "mapping = dict(zip(col_ind, row_ind))\n",
        "\n",
        "#remap labels to labels of original dataset\n",
        "y_pred_mapped = np.array([mapping[label] for label in labels])\n",
        "\n",
        "cm_mapped = confusion_matrix(y_true, y_pred_mapped)\n",
        "\n",
        "sns.heatmap(cm_mapped, annot = True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Clusters\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix: Clusters vs True Labels\")\n",
        "plt.savefig(\"confusion_matrix_blobs.png\")\n",
        "plt.show()\n",
        "\n",
        "#elbow analysis (just use the inertia values found before and plot))\n",
        "plt.plot(k_range, inertia_values, marker = \"o\")\n",
        "plt.xlabel(\"Number of clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.savefig(\"elbow_analysis_blobs.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Clustering Fashion-MNIST using $k$-means"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST from OpenML\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "X, y = fetch_openml(\"Fashion-MNIST\", version=1, as_frame=False, parser=\"auto\", return_X_y=True)\n",
        "y = y.astype(int)\n",
        "\n",
        "print(type(X),X.shape)\n",
        "print(type(y),y.shape)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "#plotting articles of clothing\n",
        "clothing_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "#take first example in each class\n",
        "unique_clothing = []\n",
        "for label in np.unique(y):\n",
        "  idx = np.where(y == label)[0][0]\n",
        "  unique_clothing.append((X[idx], label))\n",
        "\n",
        "#plot 5x2\n",
        "fig,axes = plt.subplots(5,2,figsize = (6,12))\n",
        "\n",
        "for ax, (img_flattened, label) in zip(axes.flat, unique_clothing):\n",
        "  ax.imshow(img_flattened.reshape(28,28), cmap=\"gray\")\n",
        "  ax.set_title(clothing_names[label])\n",
        "  ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"clothings.png\")\n",
        "plt.show()\n",
        "\n",
        "#k-means clusters analysis\n",
        "#standardize the dataset\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "#reduce dimensions with PCA since large dataset\n",
        "pca = PCA(n_components = 10)\n",
        "pca_X = pca.fit_transform(X)\n",
        "\n",
        "#Computing inertia values\n",
        "inertia_values = []\n",
        "k_range = range(1,21)\n",
        "\n",
        "for k in k_range:\n",
        "  kmeans = KMeans(n_clusters = k).fit(pca_X)\n",
        "  inertia_values.append(kmeans.inertia_)\n",
        "  print(\"inertia value for k-means=\", k, \"is\", inertia_values[k-1])\n",
        "\n",
        "#elbow analysis (just use the inertia values found before and plot))\n",
        "plt.plot(k_range, inertia_values, marker = \"o\")\n",
        "plt.xlabel(\"Number of clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.savefig(\"elbow_analysis_fashion.png\")\n",
        "plt.show()\n",
        "\n",
        "#initialize KMeans\n",
        "kmeans = KMeans(n_clusters = 10)\n",
        "y_pred = kmeans.fit_predict(X)\n",
        "\n",
        "#confusion matrix\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "#match clusters to actual using hungarian matching algorithm\n",
        "row_ind, col_ind = linear_sum_assignment(-cm)\n",
        "mapping = dict(zip(col_ind, row_ind))\n",
        "\n",
        "#remap labels to labels of original dataset\n",
        "y_pred_mapped = np.array([mapping[label] for label in y_pred])\n",
        "\n",
        "#evaluate results\n",
        "ari_kmeans = adjusted_rand_score(y, y_pred_mapped)\n",
        "print(f\"K-means Adjusted Rand Index (ARI): {ari_kmeans:.3f}\")\n",
        "\n",
        "cm_mapped = confusion_matrix(y, y_pred_mapped)\n",
        "\n",
        "sns.heatmap(cm_mapped, annot = True, fmt=\"d\", cmap=\"Blues\", xticklabels=clothing_names, yticklabels=clothing_names)\n",
        "plt.xlabel(\"Predicted Clusters\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix: Clusters vs True Labels\")\n",
        "plt.savefig(\"confusion_matrix_fashion_kmeans.png\")\n",
        "plt.show()\n",
        "\n",
        "#2D PCA visualization\n",
        "#initialize PCA to 2 components\n",
        "pca = PCA(n_components = 2)\n",
        "principal_components = pca.fit_transform(X)\n",
        "\n",
        "#initialize KMeans\n",
        "kmeans = KMeans(n_clusters = 7)\n",
        "kmeans.fit(X)\n",
        "\n",
        "#cluster labels\n",
        "labels = kmeans.labels_\n",
        "\n",
        "centers = pca.transform(kmeans.cluster_centers_)\n",
        "\n",
        "#plot results with PCA scaling\n",
        "plt.scatter(principal_components[:,0], principal_components[:,1], c = labels, cmap='viridis', marker='o')\n",
        "plt.scatter(centers[:,0], centers[:,1], c='red', marker = 'x', label = 'Centers')\n",
        "plt.title(\"2D PCA Visualization of K-Means Clustering\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.legend()\n",
        "plt.savefig(\"2DPCA_fashion_kmeans.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0REsDBunNmEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Dimensionality reduction for Fashion-MNIST"
      ],
      "metadata": {
        "id": "6Bpow7TrZ7iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Load Fashion-MNIST from OpenML\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "X, y = fetch_openml(\"Fashion-MNIST\", version=1, as_frame=False, parser=\"auto\", return_X_y=True)\n",
        "y = y.astype(int)\n",
        "\n",
        "print(type(X),X.shape)\n",
        "print(type(y),y.shape)\n",
        "\n",
        "#plotting articles of clothing\n",
        "clothing_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "#target dimensions to explore with PCA and random projection\n",
        "dimensions = [10, 20, 50, 100, 200]\n",
        "\n",
        "#storage setup\n",
        "pca_pearson, pca_spearman = [],[]\n",
        "rp_pearson, rp_spearman = [],[]\n",
        "\n",
        "#only sample 10000 random pairs, since dataset would be too large to compute\n",
        "n = X.shape[0]\n",
        "idx_i = np.random.randint(0, n, size = 10000)\n",
        "idx_j = np.random.randint(0, n, size = 10000)\n",
        "\n",
        "#original pairwise distances\n",
        "original_D = np.linalg.norm(X[idx_i] - X[idx_j], axis = 1)\n",
        "\n",
        "#perform pca and random projection for each target dimension\n",
        "for k in dimensions:\n",
        "  #PCA\n",
        "  pca_X = PCA(n_components = k).fit_transform(X)\n",
        "  pca_d = np.linalg.norm(pca_X[idx_i] - pca_X[idx_j], axis = 1)\n",
        "  r_p, _ = pearsonr(original_D, pca_d)\n",
        "  r_s, _ = spearmanr(original_D, pca_d)\n",
        "  pca_pearson.append(r_p)\n",
        "  pca_spearman.append(r_s)\n",
        "\n",
        "  #Random Projection\n",
        "  rp_X = GaussianRandomProjection(n_components = k).fit_transform(X)\n",
        "  rp_d = np.linalg.norm(rp_X[idx_i] - rp_X[idx_j], axis = 1)\n",
        "  r_p, _ = pearsonr(original_D, rp_d)\n",
        "  r_s, _ = spearmanr(original_D, rp_d)\n",
        "  rp_pearson.append(r_p)\n",
        "  rp_spearman.append(r_s)\n",
        "\n",
        "#plot results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
        "\n",
        "#Pearson plot\n",
        "axes[0].plot(dimensions, pca_pearson, marker=\"o\", label = \"PCA\")\n",
        "axes[0].plot(dimensions, rp_pearson, marker=\"s\", label=\"Random Projection\")\n",
        "axes[0].set_title(\"Pearson Correlation\")\n",
        "axes[0].set_xlabel(\"Target dimension k\")\n",
        "axes[0].set_ylabel(\"Correlation with original distance\")\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "#Spearman plot\n",
        "axes[1].plot(dimensions, pca_spearman, marker=\"o\", label=\"PCA\")\n",
        "axes[1].plot(dimensions, rp_spearman, marker=\"s\", label = \"Random Projection\")\n",
        "axes[1].set_title(\"Spearman Correlation\")\n",
        "axes[1].set_xlabel(\"Target dimension k\")\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.suptitle(\"PCA vs Random Projection of Fashion-MNIST\", fontsize = 14)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"PCA_vs_randomProjection.png\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ejYYENCQZ9tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Clustering Fashion-MNIST using spectral clustering"
      ],
      "metadata": {
        "id": "fOTFcjWOfCZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "# Load Fashion-MNIST from OpenML\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "X, y = fetch_openml(\"Fashion-MNIST\", version=1, as_frame=False, parser=\"auto\", return_X_y=True)\n",
        "y = y.astype(int)\n",
        "\n",
        "print(type(X),X.shape)\n",
        "print(type(y),y.shape)\n",
        "\n",
        "#plotting articles of clothing\n",
        "clothing_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n"
      ],
      "metadata": {
        "id": "MRB_nw21fI24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}